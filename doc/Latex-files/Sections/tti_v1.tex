

\cref{fig:tti}(a-d) shows effect of test time interventions.
Any concept-based models~\cite{koh2020concept, zarlenga2022concept} allow test time interventions for datasets with concept annotation (\eg CUB-200, Awa2). We identify the significant concepts via their attention scores in $g$, as during the computation of completeness scores, and set their values with the ground truths, considering the ground truth concepts as an oracle.
 As MoIE identifies a more diverse set of concepts by focusing on different subsets of classes, MoIE outperforms the baselines in terms of accuracy for such test time interventions. Instead of manually deciding the samples to intervene, it is generally preferred to intervene on the ``harder'' samples, making the process efficient. As per~\cref{Sec:residual}, experts of different iterations cover samples with increasing order of ``hardness''. To intervene efficiently, we perform identical test-time interventions with varying numbers of concepts for the ``harder'' samples covered by the final two experts and plot the accuracy in~\cref{fig:tti}(e). For the VIT-derived MoIE of CUB-200, intervening only on 20 concepts enhances the accuracy of MoIE from 91\% to 96\% ($\sim 6.1\% \uparrow$). We cannot perform the same for the baselines as they cannot directly estimate ``harder" samples. Also, \cref{fig:tti} shows a relatively higher gain for ResNet-based models in general.~\cref{app:tti_qual} demonstrates an example of test time intervention of concepts for relatively ``harder'' samples, identified by the last two experts of MoIE.