

% ML model design either starts with an interpretable model or a Blackbox and explains it post hoc.
% Blackbox models are flexible but difficult to explain, while interpretable models are inherently explainable. 
% Yet, interpretable models require extensive ML knowledge and tend to be less flexible, potentially underperforming than their Blackbox equivalents. 
% This paper aims to blur the distinction between a post hoc explanation of a Blackbox and constructing interpretable models. 
% Beginning with a Blackbox, we iteratively \emph{carve out} a mixture of interpretable models and a \emph{residual network}. 
% The interpretable models identify a subset of samples and explain them using First Order Logic (FOL), providing basic reasoning on concepts from the Blackbox. 
% We route the remaining samples through a flexible residual. 
% We repeat the method on the residual network until all the interpretable models explain the desired proportion of data. 
% Our extensive experiments show that our \emph{route, interpret, and repeat} approach
% (1) identifies a richer diverse set of instance-specific concepts with high concept completeness via interpretable models by specializing in various subsets of data   without compromising in performance,
% (2) identifies the relatively ``harder'' samples to explain via residuals,
% (3) outperforms the interpretable by-design models by significant margins during test-time interventions,
% (4) can be used to fix the shortcut learned by the original Blackbox.


ML model design either starts with an interpretable model or a Blackbox and explains it post hoc. Blackbox models are flexible but difficult to explain, while interpretable models are inherently explainable. Yet, interpretable models require extensive ML knowledge and tend to be less flexible and underperforming than their Blackbox variants. This paper aims to blur the distinction between a post hoc explanation of a Blackbox and constructing interpretable models. 
% We hypothesize that a Blackbox model encodes several interpretable models, each applicable to different portions of data. 
Beginning with a Blackbox, we iteratively \emph{carve out} a mixture of interpretable experts (MoIE) and a \emph{residual network}. Each interpretable model specializes in a subset of samples and explains them using First Order Logic (FOL), providing basic reasoning on concepts from the Blackbox. We route the remaining samples through a flexible residual. We repeat the method on the residual network until all the interpretable models explain the desired proportion of data. Our extensive experiments show that our \emph{route, interpret, and repeat} approach (1) identifies a diverse set of instance-specific concepts with high concept completeness via MoIE without compromising in performance, (2) identifies the relatively ``harder'' samples to explain via residuals, (3) outperforms the interpretable by-design models by significant margins during test-time interventions, and (4) fixes the shortcut learned by the original Blackbox. The code for MoIE is
publicly available at: \url{https://github.com/batmanlab/ICML-2023-Route-interpret-repeat}.