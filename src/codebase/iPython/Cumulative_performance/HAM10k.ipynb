{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\n\\nimport os\\nimport sys\\n\\nsys.path.append(\\n    os.path.abspath(\\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/codebase\\\")\\n)\\nimport torch.backends.cudnn as cudnn\\nimport random\\nimport time\\nfrom collections import OrderedDict\\nimport pickle\\nimport numpy as np\\nimport pandas as pd\\nimport torch\\nimport torch.nn.functional as F\\nfrom torch.utils.data import DataLoader\\nfrom tqdm import tqdm\\nfrom torch.nn.functional import one_hot\\nimport sklearn.metrics as metrics\\nimport utils\\nfrom Explainer.loss_F import loss_fn_kd, entropy_loss\\nfrom Explainer.models.Gated_Logic_Net import Gated_Logic_Net\\nfrom Explainer.models.explainer import Explainer\\nfrom Explainer.models.pi import Pi\\nfrom dataset.dataset_cubs import Dataset_cub_for_explainer\\nfrom dataset.utils_dataset import get_dataset_with_image_and_attributes\\nfrom Explainer.loss_F import loss_fn_kd, entropy_loss, Selective_Distillation_Loss\\nfrom Explainer.models.concepts import Conceptizator\\n\\nimport matplotlib.pyplot as plt\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\n\\nimport os\\nimport sys\\n\\nsys.path.append(\\n    os.path.abspath(\\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/codebase\\\")\\n)\\nimport torch.backends.cudnn as cudnn\\nimport random\\nimport time\\nfrom collections import OrderedDict\\nimport pickle\\nimport numpy as np\\nimport pandas as pd\\nimport torch\\nimport torch.nn.functional as F\\nfrom torch.utils.data import DataLoader\\nfrom tqdm import tqdm\\nfrom torch.nn.functional import one_hot\\nimport sklearn.metrics as metrics\\nimport utils\\nfrom Explainer.loss_F import loss_fn_kd, entropy_loss\\nfrom Explainer.models.Gated_Logic_Net import Gated_Logic_Net\\nfrom Explainer.models.explainer import Explainer\\nfrom Explainer.models.pi import Pi\\nfrom dataset.dataset_cubs import Dataset_cub_for_explainer\\nfrom dataset.utils_dataset import get_dataset_with_image_and_attributes\\nfrom Explainer.loss_F import loss_fn_kd, entropy_loss, Selective_Distillation_Loss\\nfrom Explainer.models.concepts import Conceptizator\\n\\nimport matplotlib.pyplot as plt\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.abspath(\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/codebase\")\n",
    ")\n",
    "import torch.backends.cudnn as cudnn\n",
    "import random\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.nn.functional import one_hot\n",
    "import sklearn.metrics as metrics\n",
    "import utils\n",
    "from Explainer.loss_F import loss_fn_kd, entropy_loss\n",
    "from Explainer.models.Gated_Logic_Net import Gated_Logic_Net\n",
    "from Explainer.models.explainer import Explainer\n",
    "from Explainer.models.pi import Pi\n",
    "from dataset.dataset_cubs import Dataset_cub_for_explainer\n",
    "from dataset.utils_dataset import get_dataset_with_image_and_attributes\n",
    "from Explainer.loss_F import loss_fn_kd, entropy_loss, Selective_Distillation_Loss\n",
    "from Explainer.models.concepts import Conceptizator\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"device = utils.get_device()\\nprint(f\\\"Device: {device}\\\")\";\n",
       "                var nbb_formatted_code = \"device = utils.get_device()\\nprint(f\\\"Device: {device}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = utils.get_device()\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################\n",
      "0.01\n",
      "0.2\n",
      "\n",
      "\n",
      " << Val sizes >>\n",
      "torch.Size([799, 2])\n",
      "torch.Size([799, 2])\n",
      "torch.Size([799])\n",
      "Auroc of Residual: 0.5 || Auroc of BB: 0.5\n",
      "Proportional Auroc: 0.19945082376435347\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"base_lr = 0.01\\nbase_cov = 0.2\\npickle_in = open(\\n    os.path.join(\\n        f\\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k/explainer/lr_{base_lr}_epochs_500_temperature-lens_0.7_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1\\\",\\n        \\\"iter1\\\",\\n        \\\"explainer/accuracy\\\",\\n        \\\"test_explainer_configs.pkl\\\",\\n    ),\\n    \\\"rb\\\",\\n)\\nargs = pickle.load(pickle_in)\\nn_classes = len(args.labels)\\nx_to_bool = 0.5\\ntop_k_explanations = 50\\nconcept_names = args.concept_names\\nprint(\\\"########################\\\")\\nprint(args.lr[0])\\nprint(args.cov[0])\\n\\nuse_concepts_as_pi_input = True\\nexplainer_init = \\\"none\\\"\\n\\nexperiment_folder = (\\n    f\\\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\\\"\\n    f\\\"_input-size-pi_{args.input_size_pi}\\\"\\n    f\\\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\\\"\\n    f\\\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\\\"\\n    f\\\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\\\"\\n)\\n\\nroot = \\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k\\\"\\nexperiment = f\\\"explainer/{experiment_folder}\\\"\\niteration = \\\"iter1\\\"\\nexpert_type = \\\"explainer/accuracy\\\"\\noutput = \\\"g_outputs\\\"\\n\\n\\n# val\\nval_tensor_preds_1 = torch.load(\\n    os.path.join(\\n        root, experiment, iteration, expert_type, output, \\\"val_tensor_preds.pt\\\"\\n    )\\n)\\n\\nval_tensor_preds_bb_1 = torch.load(\\n    os.path.join(\\n        root, experiment, iteration, expert_type, output, \\\"val_tensor_preds_bb.pt\\\"\\n    )\\n)\\n\\nval_tensor_y_1 = torch.load(\\n    os.path.join(root, experiment, iteration, expert_type, output, \\\"val_tensor_y.pt\\\")\\n)\\n\\n\\nprint(\\\"\\\\n\\\\n << Val sizes >>\\\")\\nprint(val_tensor_preds_1.size())\\nprint(val_tensor_preds_bb_1.size())\\nprint(val_tensor_y_1.size())\\n\\nval_auroc_g, _ = utils.compute_AUC(gt=val_tensor_y_1, pred=val_tensor_preds_1[:, 1])\\nval_auroc_bb, _ = utils.compute_AUC(gt=val_tensor_y_1, pred=val_tensor_preds_bb_1[:, 1])\\nprint(f\\\"Auroc of Residual: {val_auroc_g} || Auroc of BB: {val_auroc_bb}\\\")\\nprint(f\\\"Proportional Auroc: {val_auroc_g * (val_tensor_preds_bb_1.size(0)/2003)}\\\")\";\n",
       "                var nbb_formatted_code = \"base_lr = 0.01\\nbase_cov = 0.2\\npickle_in = open(\\n    os.path.join(\\n        f\\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k/explainer/lr_{base_lr}_epochs_500_temperature-lens_0.7_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1\\\",\\n        \\\"iter1\\\",\\n        \\\"explainer/accuracy\\\",\\n        \\\"test_explainer_configs.pkl\\\",\\n    ),\\n    \\\"rb\\\",\\n)\\nargs = pickle.load(pickle_in)\\nn_classes = len(args.labels)\\nx_to_bool = 0.5\\ntop_k_explanations = 50\\nconcept_names = args.concept_names\\nprint(\\\"########################\\\")\\nprint(args.lr[0])\\nprint(args.cov[0])\\n\\nuse_concepts_as_pi_input = True\\nexplainer_init = \\\"none\\\"\\n\\nexperiment_folder = (\\n    f\\\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\\\"\\n    f\\\"_input-size-pi_{args.input_size_pi}\\\"\\n    f\\\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\\\"\\n    f\\\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\\\"\\n    f\\\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\\\"\\n)\\n\\nroot = \\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k\\\"\\nexperiment = f\\\"explainer/{experiment_folder}\\\"\\niteration = \\\"iter1\\\"\\nexpert_type = \\\"explainer/accuracy\\\"\\noutput = \\\"g_outputs\\\"\\n\\n\\n# val\\nval_tensor_preds_1 = torch.load(\\n    os.path.join(\\n        root, experiment, iteration, expert_type, output, \\\"val_tensor_preds.pt\\\"\\n    )\\n)\\n\\nval_tensor_preds_bb_1 = torch.load(\\n    os.path.join(\\n        root, experiment, iteration, expert_type, output, \\\"val_tensor_preds_bb.pt\\\"\\n    )\\n)\\n\\nval_tensor_y_1 = torch.load(\\n    os.path.join(root, experiment, iteration, expert_type, output, \\\"val_tensor_y.pt\\\")\\n)\\n\\n\\nprint(\\\"\\\\n\\\\n << Val sizes >>\\\")\\nprint(val_tensor_preds_1.size())\\nprint(val_tensor_preds_bb_1.size())\\nprint(val_tensor_y_1.size())\\n\\nval_auroc_g, _ = utils.compute_AUC(gt=val_tensor_y_1, pred=val_tensor_preds_1[:, 1])\\nval_auroc_bb, _ = utils.compute_AUC(gt=val_tensor_y_1, pred=val_tensor_preds_bb_1[:, 1])\\nprint(f\\\"Auroc of Residual: {val_auroc_g} || Auroc of BB: {val_auroc_bb}\\\")\\nprint(f\\\"Proportional Auroc: {val_auroc_g * (val_tensor_preds_bb_1.size(0)/2003)}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_lr = 0.01\n",
    "base_cov = 0.2\n",
    "pickle_in = open(\n",
    "    os.path.join(\n",
    "        f\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k/explainer/lr_{base_lr}_epochs_500_temperature-lens_0.7_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1\",\n",
    "        \"iter1\",\n",
    "        \"explainer/accuracy\",\n",
    "        \"test_explainer_configs.pkl\",\n",
    "    ),\n",
    "    \"rb\",\n",
    ")\n",
    "args = pickle.load(pickle_in)\n",
    "n_classes = len(args.labels)\n",
    "x_to_bool = 0.5\n",
    "top_k_explanations = 50\n",
    "concept_names = args.concept_names\n",
    "print(\"########################\")\n",
    "print(args.lr[0])\n",
    "print(args.cov[0])\n",
    "\n",
    "use_concepts_as_pi_input = True\n",
    "explainer_init = \"none\"\n",
    "\n",
    "experiment_folder = (\n",
    "    f\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\"\n",
    "    f\"_input-size-pi_{args.input_size_pi}\"\n",
    "    f\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\"\n",
    "    f\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\"\n",
    "    f\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\"\n",
    ")\n",
    "\n",
    "root = \"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k\"\n",
    "experiment = f\"explainer/{experiment_folder}\"\n",
    "iteration = \"iter1\"\n",
    "expert_type = \"explainer/accuracy\"\n",
    "output = \"g_outputs\"\n",
    "\n",
    "\n",
    "# val\n",
    "val_tensor_preds_1 = torch.load(\n",
    "    os.path.join(\n",
    "        root, experiment, iteration, expert_type, output, \"val_tensor_preds.pt\"\n",
    "    )\n",
    ")\n",
    "\n",
    "val_tensor_preds_bb_1 = torch.load(\n",
    "    os.path.join(\n",
    "        root, experiment, iteration, expert_type, output, \"val_tensor_preds_bb.pt\"\n",
    "    )\n",
    ")\n",
    "\n",
    "val_tensor_y_1 = torch.load(\n",
    "    os.path.join(root, experiment, iteration, expert_type, output, \"val_tensor_y.pt\")\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n\\n << Val sizes >>\")\n",
    "print(val_tensor_preds_1.size())\n",
    "print(val_tensor_preds_bb_1.size())\n",
    "print(val_tensor_y_1.size())\n",
    "\n",
    "val_auroc_g, _ = utils.compute_AUC(gt=val_tensor_y_1, pred=val_tensor_preds_1[:, 1])\n",
    "val_auroc_bb, _ = utils.compute_AUC(gt=val_tensor_y_1, pred=val_tensor_preds_bb_1[:, 1])\n",
    "print(f\"Auroc of Residual: {val_auroc_g} || Auroc of BB: {val_auroc_bb}\")\n",
    "print(f\"Proportional Auroc: {val_auroc_g * (val_tensor_preds_bb_1.size(0)/2003)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################\n",
      "0.01\n",
      "0.2\n",
      "\n",
      "\n",
      " << Val sizes >>\n",
      "torch.Size([231, 2])\n",
      "torch.Size([231, 2])\n",
      "torch.Size([231])\n",
      "Auroc of Residual: 0.6615720524017468 || Auroc of BB: 0.8165938864628821\n",
      "Proportional Auroc: 0.07629712636285747\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"base_lr = 0.01\\nbase_cov = 0.2\\npickle_in = open(\\n    os.path.join(\\n        f\\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k/explainer/lr_{base_lr}_epochs_500_temperature-lens_0.7_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1\\\",\\n        \\\"cov_0.2\\\",\\n        \\\"iter2\\\",\\n        \\\"explainer/accuracy\\\",\\n        \\\"test_explainer_configs.pkl\\\",\\n    ),\\n    \\\"rb\\\",\\n)\\nargs = pickle.load(pickle_in)\\nn_classes = len(args.labels)\\nx_to_bool = 0.5\\ntop_k_explanations = 50\\nconcept_names = args.concept_names\\nprint(\\\"########################\\\")\\nprint(args.lr[-1])\\nprint(args.cov[-1])\\n\\nuse_concepts_as_pi_input = True\\nexplainer_init = \\\"none\\\"\\n\\nexperiment_folder = (\\n    f\\\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\\\"\\n    f\\\"_input-size-pi_{args.input_size_pi}\\\"\\n    f\\\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\\\"\\n    f\\\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\\\"\\n    f\\\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\\\"\\n)\\n\\nroot = \\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k\\\"\\nexperiment = f\\\"explainer/{experiment_folder}\\\"\\niteration = \\\"iter2\\\"\\nexpert_type = \\\"explainer/accuracy\\\"\\noutput = \\\"g_outputs\\\"\\n\\n# val\\nval_tensor_preds_2 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_preds.pt\\\",\\n    )\\n)\\n\\nval_tensor_preds_bb_2 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_preds_bb.pt\\\",\\n    )\\n)\\n\\nval_tensor_y_2 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_y.pt\\\",\\n    )\\n)\\n\\n\\nprint(\\\"\\\\n\\\\n << Val sizes >>\\\")\\nprint(val_tensor_preds_2.size())\\nprint(val_tensor_preds_bb_2.size())\\nprint(val_tensor_y_2.size())\\n\\nval_auroc_g, _ = utils.compute_AUC(gt=val_tensor_y_2, pred=val_tensor_preds_2[:, 1])\\nval_auroc_bb, _ = utils.compute_AUC(gt=val_tensor_y_2, pred=val_tensor_preds_bb_2[:, 1])\\nprint(f\\\"Auroc of Residual: {val_auroc_g} || Auroc of BB: {val_auroc_bb}\\\")\\nprint(f\\\"Proportional Auroc: {val_auroc_g * (val_tensor_preds_bb_2.size(0)/2003)}\\\")\";\n",
       "                var nbb_formatted_code = \"base_lr = 0.01\\nbase_cov = 0.2\\npickle_in = open(\\n    os.path.join(\\n        f\\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k/explainer/lr_{base_lr}_epochs_500_temperature-lens_0.7_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1\\\",\\n        \\\"cov_0.2\\\",\\n        \\\"iter2\\\",\\n        \\\"explainer/accuracy\\\",\\n        \\\"test_explainer_configs.pkl\\\",\\n    ),\\n    \\\"rb\\\",\\n)\\nargs = pickle.load(pickle_in)\\nn_classes = len(args.labels)\\nx_to_bool = 0.5\\ntop_k_explanations = 50\\nconcept_names = args.concept_names\\nprint(\\\"########################\\\")\\nprint(args.lr[-1])\\nprint(args.cov[-1])\\n\\nuse_concepts_as_pi_input = True\\nexplainer_init = \\\"none\\\"\\n\\nexperiment_folder = (\\n    f\\\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\\\"\\n    f\\\"_input-size-pi_{args.input_size_pi}\\\"\\n    f\\\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\\\"\\n    f\\\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\\\"\\n    f\\\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\\\"\\n)\\n\\nroot = \\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k\\\"\\nexperiment = f\\\"explainer/{experiment_folder}\\\"\\niteration = \\\"iter2\\\"\\nexpert_type = \\\"explainer/accuracy\\\"\\noutput = \\\"g_outputs\\\"\\n\\n# val\\nval_tensor_preds_2 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_preds.pt\\\",\\n    )\\n)\\n\\nval_tensor_preds_bb_2 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_preds_bb.pt\\\",\\n    )\\n)\\n\\nval_tensor_y_2 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_y.pt\\\",\\n    )\\n)\\n\\n\\nprint(\\\"\\\\n\\\\n << Val sizes >>\\\")\\nprint(val_tensor_preds_2.size())\\nprint(val_tensor_preds_bb_2.size())\\nprint(val_tensor_y_2.size())\\n\\nval_auroc_g, _ = utils.compute_AUC(gt=val_tensor_y_2, pred=val_tensor_preds_2[:, 1])\\nval_auroc_bb, _ = utils.compute_AUC(gt=val_tensor_y_2, pred=val_tensor_preds_bb_2[:, 1])\\nprint(f\\\"Auroc of Residual: {val_auroc_g} || Auroc of BB: {val_auroc_bb}\\\")\\nprint(f\\\"Proportional Auroc: {val_auroc_g * (val_tensor_preds_bb_2.size(0)/2003)}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_lr = 0.01\n",
    "base_cov = 0.2\n",
    "pickle_in = open(\n",
    "    os.path.join(\n",
    "        f\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k/explainer/lr_{base_lr}_epochs_500_temperature-lens_0.7_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1\",\n",
    "        \"cov_0.2\",\n",
    "        \"iter2\",\n",
    "        \"explainer/accuracy\",\n",
    "        \"test_explainer_configs.pkl\",\n",
    "    ),\n",
    "    \"rb\",\n",
    ")\n",
    "args = pickle.load(pickle_in)\n",
    "n_classes = len(args.labels)\n",
    "x_to_bool = 0.5\n",
    "top_k_explanations = 50\n",
    "concept_names = args.concept_names\n",
    "print(\"########################\")\n",
    "print(args.lr[-1])\n",
    "print(args.cov[-1])\n",
    "\n",
    "use_concepts_as_pi_input = True\n",
    "explainer_init = \"none\"\n",
    "\n",
    "experiment_folder = (\n",
    "    f\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\"\n",
    "    f\"_input-size-pi_{args.input_size_pi}\"\n",
    "    f\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\"\n",
    "    f\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\"\n",
    "    f\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\"\n",
    ")\n",
    "\n",
    "root = \"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k\"\n",
    "experiment = f\"explainer/{experiment_folder}\"\n",
    "iteration = \"iter2\"\n",
    "expert_type = \"explainer/accuracy\"\n",
    "output = \"g_outputs\"\n",
    "\n",
    "# val\n",
    "val_tensor_preds_2 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        f\"cov_{args.cov[-1]}\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"val_tensor_preds.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "val_tensor_preds_bb_2 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        f\"cov_{args.cov[-1]}\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"val_tensor_preds_bb.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "val_tensor_y_2 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        f\"cov_{args.cov[-1]}\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"val_tensor_y.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n\\n << Val sizes >>\")\n",
    "print(val_tensor_preds_2.size())\n",
    "print(val_tensor_preds_bb_2.size())\n",
    "print(val_tensor_y_2.size())\n",
    "\n",
    "val_auroc_g, _ = utils.compute_AUC(gt=val_tensor_y_2, pred=val_tensor_preds_2[:, 1])\n",
    "val_auroc_bb, _ = utils.compute_AUC(gt=val_tensor_y_2, pred=val_tensor_preds_bb_2[:, 1])\n",
    "print(f\"Auroc of Residual: {val_auroc_g} || Auroc of BB: {val_auroc_bb}\")\n",
    "print(f\"Proportional Auroc: {val_auroc_g * (val_tensor_preds_bb_2.size(0)/2003)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################\n",
      "0.01\n",
      "0.2\n",
      "\n",
      "\n",
      " << Val sizes >>\n",
      "torch.Size([303, 2])\n",
      "torch.Size([303, 2])\n",
      "torch.Size([303])\n",
      "Auroc of Residual: 0.6323163138231631 || Auroc of BB: 0.7341220423412205\n",
      "Proportional Auroc: 0.25223201934333866\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"base_lr = 0.01\\nbase_cov = 0.2\\npickle_in = open(\\n    os.path.join(\\n        f\\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k/explainer/lr_{base_lr}_epochs_500_temperature-lens_0.7_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1\\\",\\n        \\\"cov_0.2\\\",\\n        \\\"iter3\\\",\\n        \\\"explainer/accuracy\\\",\\n        \\\"test_explainer_configs.pkl\\\",\\n    ),\\n    \\\"rb\\\",\\n)\\nargs = pickle.load(pickle_in)\\nn_classes = len(args.labels)\\nx_to_bool = 0.5\\ntop_k_explanations = 50\\nconcept_names = args.concept_names\\nprint(\\\"########################\\\")\\nprint(args.lr[-1])\\nprint(args.cov[-1])\\n\\nuse_concepts_as_pi_input = True\\nexplainer_init = \\\"none\\\"\\n\\nexperiment_folder = (\\n    f\\\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\\\"\\n    f\\\"_input-size-pi_{args.input_size_pi}\\\"\\n    f\\\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\\\"\\n    f\\\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\\\"\\n    f\\\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\\\"\\n)\\n\\nroot = \\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k\\\"\\nexperiment = f\\\"explainer/{experiment_folder}\\\"\\niteration = \\\"iter3\\\"\\nexpert_type = \\\"explainer/accuracy\\\"\\noutput = \\\"g_outputs\\\"\\n\\n# val\\nval_tensor_preds_3 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_preds.pt\\\",\\n    )\\n)\\n\\nval_tensor_preds_bb_3 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_preds_bb.pt\\\",\\n    )\\n)\\n\\nval_tensor_y_3 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_y.pt\\\",\\n    )\\n)\\n\\n\\nprint(\\\"\\\\n\\\\n << Val sizes >>\\\")\\nprint(val_tensor_preds_3.size())\\nprint(val_tensor_preds_bb_3.size())\\nprint(val_tensor_y_3.size())\\n\\nval_auroc_g, _ = utils.compute_AUC(gt=val_tensor_y_3, pred=val_tensor_preds_3[:, 1])\\nval_auroc_bb, _ = utils.compute_AUC(gt=val_tensor_y_3, pred=val_tensor_preds_bb_3[:, 1])\\nprint(f\\\"Auroc of Residual: {val_auroc_g} || Auroc of BB: {val_auroc_bb}\\\")\\nprint(f\\\"Proportional Auroc: {val_auroc_g * (val_tensor_preds_bb_1.size(0)/2003)}\\\")\";\n",
       "                var nbb_formatted_code = \"base_lr = 0.01\\nbase_cov = 0.2\\npickle_in = open(\\n    os.path.join(\\n        f\\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k/explainer/lr_{base_lr}_epochs_500_temperature-lens_0.7_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1\\\",\\n        \\\"cov_0.2\\\",\\n        \\\"iter3\\\",\\n        \\\"explainer/accuracy\\\",\\n        \\\"test_explainer_configs.pkl\\\",\\n    ),\\n    \\\"rb\\\",\\n)\\nargs = pickle.load(pickle_in)\\nn_classes = len(args.labels)\\nx_to_bool = 0.5\\ntop_k_explanations = 50\\nconcept_names = args.concept_names\\nprint(\\\"########################\\\")\\nprint(args.lr[-1])\\nprint(args.cov[-1])\\n\\nuse_concepts_as_pi_input = True\\nexplainer_init = \\\"none\\\"\\n\\nexperiment_folder = (\\n    f\\\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\\\"\\n    f\\\"_input-size-pi_{args.input_size_pi}\\\"\\n    f\\\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\\\"\\n    f\\\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\\\"\\n    f\\\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\\\"\\n)\\n\\nroot = \\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k\\\"\\nexperiment = f\\\"explainer/{experiment_folder}\\\"\\niteration = \\\"iter3\\\"\\nexpert_type = \\\"explainer/accuracy\\\"\\noutput = \\\"g_outputs\\\"\\n\\n# val\\nval_tensor_preds_3 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_preds.pt\\\",\\n    )\\n)\\n\\nval_tensor_preds_bb_3 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_preds_bb.pt\\\",\\n    )\\n)\\n\\nval_tensor_y_3 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_y.pt\\\",\\n    )\\n)\\n\\n\\nprint(\\\"\\\\n\\\\n << Val sizes >>\\\")\\nprint(val_tensor_preds_3.size())\\nprint(val_tensor_preds_bb_3.size())\\nprint(val_tensor_y_3.size())\\n\\nval_auroc_g, _ = utils.compute_AUC(gt=val_tensor_y_3, pred=val_tensor_preds_3[:, 1])\\nval_auroc_bb, _ = utils.compute_AUC(gt=val_tensor_y_3, pred=val_tensor_preds_bb_3[:, 1])\\nprint(f\\\"Auroc of Residual: {val_auroc_g} || Auroc of BB: {val_auroc_bb}\\\")\\nprint(f\\\"Proportional Auroc: {val_auroc_g * (val_tensor_preds_bb_1.size(0)/2003)}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_lr = 0.01\n",
    "base_cov = 0.2\n",
    "pickle_in = open(\n",
    "    os.path.join(\n",
    "        f\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k/explainer/lr_{base_lr}_epochs_500_temperature-lens_0.7_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1\",\n",
    "        \"cov_0.2\",\n",
    "        \"iter3\",\n",
    "        \"explainer/accuracy\",\n",
    "        \"test_explainer_configs.pkl\",\n",
    "    ),\n",
    "    \"rb\",\n",
    ")\n",
    "args = pickle.load(pickle_in)\n",
    "n_classes = len(args.labels)\n",
    "x_to_bool = 0.5\n",
    "top_k_explanations = 50\n",
    "concept_names = args.concept_names\n",
    "print(\"########################\")\n",
    "print(args.lr[-1])\n",
    "print(args.cov[-1])\n",
    "\n",
    "use_concepts_as_pi_input = True\n",
    "explainer_init = \"none\"\n",
    "\n",
    "experiment_folder = (\n",
    "    f\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\"\n",
    "    f\"_input-size-pi_{args.input_size_pi}\"\n",
    "    f\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\"\n",
    "    f\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\"\n",
    "    f\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\"\n",
    ")\n",
    "\n",
    "root = \"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k\"\n",
    "experiment = f\"explainer/{experiment_folder}\"\n",
    "iteration = \"iter3\"\n",
    "expert_type = \"explainer/accuracy\"\n",
    "output = \"g_outputs\"\n",
    "\n",
    "# val\n",
    "val_tensor_preds_3 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        f\"cov_{args.cov[-1]}\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"val_tensor_preds.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "val_tensor_preds_bb_3 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        f\"cov_{args.cov[-1]}\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"val_tensor_preds_bb.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "val_tensor_y_3 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        f\"cov_{args.cov[-1]}\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"val_tensor_y.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n\\n << Val sizes >>\")\n",
    "print(val_tensor_preds_3.size())\n",
    "print(val_tensor_preds_bb_3.size())\n",
    "print(val_tensor_y_3.size())\n",
    "\n",
    "val_auroc_g, _ = utils.compute_AUC(gt=val_tensor_y_3, pred=val_tensor_preds_3[:, 1])\n",
    "val_auroc_bb, _ = utils.compute_AUC(gt=val_tensor_y_3, pred=val_tensor_preds_bb_3[:, 1])\n",
    "print(f\"Auroc of Residual: {val_auroc_g} || Auroc of BB: {val_auroc_bb}\")\n",
    "print(f\"Proportional Auroc: {val_auroc_g * (val_tensor_preds_bb_3.size(0)/2003)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################\n",
      "0.01\n",
      "0.2\n",
      "\n",
      "\n",
      " << Val sizes >>\n",
      "torch.Size([203, 2])\n",
      "torch.Size([203, 2])\n",
      "torch.Size([203])\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"base_lr = 0.01\\nbase_cov = 0.2\\npickle_in = open(\\n    os.path.join(\\n        f\\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k/explainer/lr_{base_lr}_epochs_500_temperature-lens_0.7_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1\\\",\\n        \\\"cov_0.2\\\",\\n        \\\"iter4\\\",\\n        \\\"explainer/accuracy\\\",\\n        \\\"test_explainer_configs.pkl\\\",\\n    ),\\n    \\\"rb\\\",\\n)\\nargs = pickle.load(pickle_in)\\nn_classes = len(args.labels)\\nx_to_bool = 0.5\\ntop_k_explanations = 50\\nconcept_names = args.concept_names\\nprint(\\\"########################\\\")\\nprint(args.lr[-1])\\nprint(args.cov[-1])\\n\\nuse_concepts_as_pi_input = True\\nexplainer_init = \\\"none\\\"\\n\\nexperiment_folder = (\\n    f\\\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\\\"\\n    f\\\"_input-size-pi_{args.input_size_pi}\\\"\\n    f\\\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\\\"\\n    f\\\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\\\"\\n    f\\\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\\\"\\n)\\n\\nroot = \\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k\\\"\\nexperiment = f\\\"explainer/{experiment_folder}\\\"\\niteration = \\\"iter4\\\"\\nexpert_type = \\\"explainer/accuracy\\\"\\noutput = \\\"g_outputs\\\"\\n\\n# val\\nval_tensor_preds_4 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_preds.pt\\\",\\n    )\\n)\\n\\nval_tensor_preds_bb_4 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_preds_bb.pt\\\",\\n    )\\n)\\n\\nval_tensor_y_4 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_y.pt\\\",\\n    )\\n)\\n\\n\\nprint(\\\"\\\\n\\\\n << Val sizes >>\\\")\\nprint(val_tensor_preds_4.size())\\nprint(val_tensor_preds_bb_4.size())\\nprint(val_tensor_y_4.size())\";\n",
       "                var nbb_formatted_code = \"base_lr = 0.01\\nbase_cov = 0.2\\npickle_in = open(\\n    os.path.join(\\n        f\\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k/explainer/lr_{base_lr}_epochs_500_temperature-lens_0.7_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1\\\",\\n        \\\"cov_0.2\\\",\\n        \\\"iter4\\\",\\n        \\\"explainer/accuracy\\\",\\n        \\\"test_explainer_configs.pkl\\\",\\n    ),\\n    \\\"rb\\\",\\n)\\nargs = pickle.load(pickle_in)\\nn_classes = len(args.labels)\\nx_to_bool = 0.5\\ntop_k_explanations = 50\\nconcept_names = args.concept_names\\nprint(\\\"########################\\\")\\nprint(args.lr[-1])\\nprint(args.cov[-1])\\n\\nuse_concepts_as_pi_input = True\\nexplainer_init = \\\"none\\\"\\n\\nexperiment_folder = (\\n    f\\\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\\\"\\n    f\\\"_input-size-pi_{args.input_size_pi}\\\"\\n    f\\\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\\\"\\n    f\\\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\\\"\\n    f\\\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\\\"\\n)\\n\\nroot = \\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k\\\"\\nexperiment = f\\\"explainer/{experiment_folder}\\\"\\niteration = \\\"iter4\\\"\\nexpert_type = \\\"explainer/accuracy\\\"\\noutput = \\\"g_outputs\\\"\\n\\n# val\\nval_tensor_preds_4 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_preds.pt\\\",\\n    )\\n)\\n\\nval_tensor_preds_bb_4 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_preds_bb.pt\\\",\\n    )\\n)\\n\\nval_tensor_y_4 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_y.pt\\\",\\n    )\\n)\\n\\n\\nprint(\\\"\\\\n\\\\n << Val sizes >>\\\")\\nprint(val_tensor_preds_4.size())\\nprint(val_tensor_preds_bb_4.size())\\nprint(val_tensor_y_4.size())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_lr = 0.01\n",
    "base_cov = 0.2\n",
    "pickle_in = open(\n",
    "    os.path.join(\n",
    "        f\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k/explainer/lr_{base_lr}_epochs_500_temperature-lens_0.7_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1\",\n",
    "        \"cov_0.2\",\n",
    "        \"iter4\",\n",
    "        \"explainer/accuracy\",\n",
    "        \"test_explainer_configs.pkl\",\n",
    "    ),\n",
    "    \"rb\",\n",
    ")\n",
    "args = pickle.load(pickle_in)\n",
    "n_classes = len(args.labels)\n",
    "x_to_bool = 0.5\n",
    "top_k_explanations = 50\n",
    "concept_names = args.concept_names\n",
    "print(\"########################\")\n",
    "print(args.lr[-1])\n",
    "print(args.cov[-1])\n",
    "\n",
    "use_concepts_as_pi_input = True\n",
    "explainer_init = \"none\"\n",
    "\n",
    "experiment_folder = (\n",
    "    f\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\"\n",
    "    f\"_input-size-pi_{args.input_size_pi}\"\n",
    "    f\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\"\n",
    "    f\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\"\n",
    "    f\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\"\n",
    ")\n",
    "\n",
    "root = \"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k\"\n",
    "experiment = f\"explainer/{experiment_folder}\"\n",
    "iteration = \"iter4\"\n",
    "expert_type = \"explainer/accuracy\"\n",
    "output = \"g_outputs\"\n",
    "\n",
    "# val\n",
    "val_tensor_preds_4 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        f\"cov_{args.cov[-1]}\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"val_tensor_preds.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "val_tensor_preds_bb_4 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        f\"cov_{args.cov[-1]}\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"val_tensor_preds_bb.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "val_tensor_y_4 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        f\"cov_{args.cov[-1]}\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"val_tensor_y.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n\\n << Val sizes >>\")\n",
    "print(val_tensor_preds_4.size())\n",
    "print(val_tensor_preds_bb_4.size())\n",
    "print(val_tensor_y_4.size())\n",
    "\n",
    "val_auroc_g, _ = utils.compute_AUC(gt=val_tensor_y_4, pred=val_tensor_preds_4[:, 1])\n",
    "val_auroc_bb, _ = utils.compute_AUC(gt=val_tensor_y_4, pred=val_tensor_preds_bb_4[:, 1])\n",
    "print(f\"Auroc of Residual: {val_auroc_g} || Auroc of BB: {val_auroc_bb}\")\n",
    "print(f\"Proportional Auroc: {val_auroc_g * (val_tensor_preds_bb_4.size(0)/2003)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################\n",
      "0.01\n",
      "0.2\n",
      "\n",
      "\n",
      " << Val sizes >>\n",
      "torch.Size([126, 2])\n",
      "torch.Size([126, 2])\n",
      "torch.Size([126])\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"base_lr = 0.01\\nbase_cov = 0.2\\npickle_in = open(\\n    os.path.join(\\n        f\\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k/explainer/lr_{base_lr}_epochs_500_temperature-lens_0.7_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1\\\",\\n        \\\"cov_0.2\\\",\\n        \\\"iter5\\\",\\n        \\\"explainer/accuracy\\\",\\n        \\\"test_explainer_configs.pkl\\\",\\n    ),\\n    \\\"rb\\\",\\n)\\nargs = pickle.load(pickle_in)\\nn_classes = len(args.labels)\\nx_to_bool = 0.5\\ntop_k_explanations = 50\\nconcept_names = args.concept_names\\nprint(\\\"########################\\\")\\nprint(args.lr[-1])\\nprint(args.cov[-1])\\n\\nuse_concepts_as_pi_input = True\\nexplainer_init = \\\"none\\\"\\n\\nexperiment_folder = (\\n    f\\\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\\\"\\n    f\\\"_input-size-pi_{args.input_size_pi}\\\"\\n    f\\\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\\\"\\n    f\\\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\\\"\\n    f\\\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\\\"\\n)\\n\\nroot = \\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k\\\"\\nexperiment = f\\\"explainer/{experiment_folder}\\\"\\niteration = \\\"iter5\\\"\\nexpert_type = \\\"explainer/accuracy\\\"\\noutput = \\\"g_outputs\\\"\\n\\n# val\\nval_tensor_preds_5 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_preds.pt\\\",\\n    )\\n)\\n\\nval_tensor_preds_bb_5 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_preds_bb.pt\\\",\\n    )\\n)\\n\\nval_tensor_y_5 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_y.pt\\\",\\n    )\\n)\\n\\n\\nprint(\\\"\\\\n\\\\n << Val sizes >>\\\")\\nprint(val_tensor_preds_5.size())\\nprint(val_tensor_preds_bb_5.size())\\nprint(val_tensor_y_5.size())\";\n",
       "                var nbb_formatted_code = \"base_lr = 0.01\\nbase_cov = 0.2\\npickle_in = open(\\n    os.path.join(\\n        f\\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k/explainer/lr_{base_lr}_epochs_500_temperature-lens_0.7_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1\\\",\\n        \\\"cov_0.2\\\",\\n        \\\"iter5\\\",\\n        \\\"explainer/accuracy\\\",\\n        \\\"test_explainer_configs.pkl\\\",\\n    ),\\n    \\\"rb\\\",\\n)\\nargs = pickle.load(pickle_in)\\nn_classes = len(args.labels)\\nx_to_bool = 0.5\\ntop_k_explanations = 50\\nconcept_names = args.concept_names\\nprint(\\\"########################\\\")\\nprint(args.lr[-1])\\nprint(args.cov[-1])\\n\\nuse_concepts_as_pi_input = True\\nexplainer_init = \\\"none\\\"\\n\\nexperiment_folder = (\\n    f\\\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\\\"\\n    f\\\"_input-size-pi_{args.input_size_pi}\\\"\\n    f\\\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\\\"\\n    f\\\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\\\"\\n    f\\\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\\\"\\n)\\n\\nroot = \\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k\\\"\\nexperiment = f\\\"explainer/{experiment_folder}\\\"\\niteration = \\\"iter5\\\"\\nexpert_type = \\\"explainer/accuracy\\\"\\noutput = \\\"g_outputs\\\"\\n\\n# val\\nval_tensor_preds_5 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_preds.pt\\\",\\n    )\\n)\\n\\nval_tensor_preds_bb_5 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_preds_bb.pt\\\",\\n    )\\n)\\n\\nval_tensor_y_5 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_y.pt\\\",\\n    )\\n)\\n\\n\\nprint(\\\"\\\\n\\\\n << Val sizes >>\\\")\\nprint(val_tensor_preds_5.size())\\nprint(val_tensor_preds_bb_5.size())\\nprint(val_tensor_y_5.size())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_lr = 0.01\n",
    "base_cov = 0.2\n",
    "pickle_in = open(\n",
    "    os.path.join(\n",
    "        f\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k/explainer/lr_{base_lr}_epochs_500_temperature-lens_0.7_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1\",\n",
    "        \"cov_0.2\",\n",
    "        \"iter5\",\n",
    "        \"explainer/accuracy\",\n",
    "        \"test_explainer_configs.pkl\",\n",
    "    ),\n",
    "    \"rb\",\n",
    ")\n",
    "args = pickle.load(pickle_in)\n",
    "n_classes = len(args.labels)\n",
    "x_to_bool = 0.5\n",
    "top_k_explanations = 50\n",
    "concept_names = args.concept_names\n",
    "print(\"########################\")\n",
    "print(args.lr[-1])\n",
    "print(args.cov[-1])\n",
    "\n",
    "use_concepts_as_pi_input = True\n",
    "explainer_init = \"none\"\n",
    "\n",
    "experiment_folder = (\n",
    "    f\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\"\n",
    "    f\"_input-size-pi_{args.input_size_pi}\"\n",
    "    f\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\"\n",
    "    f\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\"\n",
    "    f\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\"\n",
    ")\n",
    "\n",
    "root = \"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k\"\n",
    "experiment = f\"explainer/{experiment_folder}\"\n",
    "iteration = \"iter5\"\n",
    "expert_type = \"explainer/accuracy\"\n",
    "output = \"g_outputs\"\n",
    "\n",
    "# val\n",
    "val_tensor_preds_5 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        f\"cov_{args.cov[-1]}\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"val_tensor_preds.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "val_tensor_preds_bb_5 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        f\"cov_{args.cov[-1]}\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"val_tensor_preds_bb.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "val_tensor_y_5 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        f\"cov_{args.cov[-1]}\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"val_tensor_y.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n\\n << Val sizes >>\")\n",
    "print(val_tensor_preds_5.size())\n",
    "print(val_tensor_preds_bb_5.size())\n",
    "print(val_tensor_y_5.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################\n",
      "0.01\n",
      "0.2\n",
      "\n",
      "\n",
      " << Val sizes >>\n",
      "torch.Size([154, 2])\n",
      "torch.Size([154, 2])\n",
      "torch.Size([154])\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"base_lr = 0.01\\nbase_cov = 0.2\\npickle_in = open(\\n    os.path.join(\\n        f\\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k/explainer/lr_{base_lr}_epochs_500_temperature-lens_0.7_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1\\\",\\n        \\\"cov_0.2\\\",\\n        \\\"iter6\\\",\\n        \\\"explainer/accuracy\\\",\\n        \\\"test_explainer_configs.pkl\\\",\\n    ),\\n    \\\"rb\\\",\\n)\\nargs = pickle.load(pickle_in)\\nn_classes = len(args.labels)\\nx_to_bool = 0.5\\ntop_k_explanations = 50\\nconcept_names = args.concept_names\\nprint(\\\"########################\\\")\\nprint(args.lr[-1])\\nprint(args.cov[-1])\\n\\nuse_concepts_as_pi_input = True\\nexplainer_init = \\\"none\\\"\\n\\nexperiment_folder = (\\n    f\\\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\\\"\\n    f\\\"_input-size-pi_{args.input_size_pi}\\\"\\n    f\\\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\\\"\\n    f\\\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\\\"\\n    f\\\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\\\"\\n)\\n\\nroot = \\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k\\\"\\nexperiment = f\\\"explainer/{experiment_folder}\\\"\\niteration = \\\"iter6\\\"\\nexpert_type = \\\"explainer/accuracy\\\"\\noutput = \\\"g_outputs\\\"\\n\\n# val\\nval_tensor_preds_6 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_preds.pt\\\",\\n    )\\n)\\n\\nval_tensor_preds_bb_6 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_preds_bb.pt\\\",\\n    )\\n)\\n\\nval_tensor_y_6 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_y.pt\\\",\\n    )\\n)\\n\\n\\nprint(\\\"\\\\n\\\\n << Val sizes >>\\\")\\nprint(val_tensor_preds_6.size())\\nprint(val_tensor_preds_bb_6.size())\\nprint(val_tensor_y_6.size())\";\n",
       "                var nbb_formatted_code = \"base_lr = 0.01\\nbase_cov = 0.2\\npickle_in = open(\\n    os.path.join(\\n        f\\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k/explainer/lr_{base_lr}_epochs_500_temperature-lens_0.7_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1\\\",\\n        \\\"cov_0.2\\\",\\n        \\\"iter6\\\",\\n        \\\"explainer/accuracy\\\",\\n        \\\"test_explainer_configs.pkl\\\",\\n    ),\\n    \\\"rb\\\",\\n)\\nargs = pickle.load(pickle_in)\\nn_classes = len(args.labels)\\nx_to_bool = 0.5\\ntop_k_explanations = 50\\nconcept_names = args.concept_names\\nprint(\\\"########################\\\")\\nprint(args.lr[-1])\\nprint(args.cov[-1])\\n\\nuse_concepts_as_pi_input = True\\nexplainer_init = \\\"none\\\"\\n\\nexperiment_folder = (\\n    f\\\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\\\"\\n    f\\\"_input-size-pi_{args.input_size_pi}\\\"\\n    f\\\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\\\"\\n    f\\\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\\\"\\n    f\\\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\\\"\\n)\\n\\nroot = \\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k\\\"\\nexperiment = f\\\"explainer/{experiment_folder}\\\"\\niteration = \\\"iter6\\\"\\nexpert_type = \\\"explainer/accuracy\\\"\\noutput = \\\"g_outputs\\\"\\n\\n# val\\nval_tensor_preds_6 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_preds.pt\\\",\\n    )\\n)\\n\\nval_tensor_preds_bb_6 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_preds_bb.pt\\\",\\n    )\\n)\\n\\nval_tensor_y_6 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        f\\\"cov_{args.cov[-1]}\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"val_tensor_y.pt\\\",\\n    )\\n)\\n\\n\\nprint(\\\"\\\\n\\\\n << Val sizes >>\\\")\\nprint(val_tensor_preds_6.size())\\nprint(val_tensor_preds_bb_6.size())\\nprint(val_tensor_y_6.size())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_lr = 0.01\n",
    "base_cov = 0.2\n",
    "pickle_in = open(\n",
    "    os.path.join(\n",
    "        f\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k/explainer/lr_{base_lr}_epochs_500_temperature-lens_0.7_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1\",\n",
    "        \"cov_0.2\",\n",
    "        \"iter6\",\n",
    "        \"explainer/accuracy\",\n",
    "        \"test_explainer_configs.pkl\",\n",
    "    ),\n",
    "    \"rb\",\n",
    ")\n",
    "args = pickle.load(pickle_in)\n",
    "n_classes = len(args.labels)\n",
    "x_to_bool = 0.5\n",
    "top_k_explanations = 50\n",
    "concept_names = args.concept_names\n",
    "print(\"########################\")\n",
    "print(args.lr[-1])\n",
    "print(args.cov[-1])\n",
    "\n",
    "use_concepts_as_pi_input = True\n",
    "explainer_init = \"none\"\n",
    "\n",
    "experiment_folder = (\n",
    "    f\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\"\n",
    "    f\"_input-size-pi_{args.input_size_pi}\"\n",
    "    f\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\"\n",
    "    f\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\"\n",
    "    f\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\"\n",
    ")\n",
    "\n",
    "root = \"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k\"\n",
    "experiment = f\"explainer/{experiment_folder}\"\n",
    "iteration = \"iter6\"\n",
    "expert_type = \"explainer/accuracy\"\n",
    "output = \"g_outputs\"\n",
    "\n",
    "# val\n",
    "val_tensor_preds_6 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        f\"cov_{args.cov[-1]}\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"val_tensor_preds.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "val_tensor_preds_bb_6 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        f\"cov_{args.cov[-1]}\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"val_tensor_preds_bb.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "val_tensor_y_6 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        f\"cov_{args.cov[-1]}\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"val_tensor_y.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n\\n << Val sizes >>\")\n",
    "print(val_tensor_preds_6.size())\n",
    "print(val_tensor_preds_bb_6.size())\n",
    "print(val_tensor_y_6.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"expert_type = \\\"explainer\\\"\\noutput = \\\"g_outputs\\\"\\n\\npreds = torch.cat(\\n    (\\n        val_tensor_preds_1, val_tensor_preds_2, val_tensor_preds_3, \\n        val_tensor_preds_4, val_tensor_preds_5, val_tensor_preds_6\\n    ), dim=0\\n)\\ngt = torch.cat(\\n    (\\n        val_tensor_y_1, val_tensor_y_2, val_tensor_y_3 ,val_tensor_y_4,\\n        val_tensor_y_5, val_tensor_y_6\\n    ), dim=0\\n)\\nbb = torch.cat(\\n    (\\n        val_tensor_preds_bb_1.cpu(), val_tensor_preds_bb_2.cpu(), val_tensor_preds_bb_3.cpu(),\\n        val_tensor_preds_bb_4.cpu(), val_tensor_preds_bb_5.cpu(), val_tensor_preds_bb_6.cpu()\\n    ),dim=0\\n)\";\n",
       "                var nbb_formatted_code = \"expert_type = \\\"explainer\\\"\\noutput = \\\"g_outputs\\\"\\n\\npreds = torch.cat(\\n    (\\n        val_tensor_preds_1,\\n        val_tensor_preds_2,\\n        val_tensor_preds_3,\\n        val_tensor_preds_4,\\n        val_tensor_preds_5,\\n        val_tensor_preds_6,\\n    ),\\n    dim=0,\\n)\\ngt = torch.cat(\\n    (\\n        val_tensor_y_1,\\n        val_tensor_y_2,\\n        val_tensor_y_3,\\n        val_tensor_y_4,\\n        val_tensor_y_5,\\n        val_tensor_y_6,\\n    ),\\n    dim=0,\\n)\\nbb = torch.cat(\\n    (\\n        val_tensor_preds_bb_1.cpu(),\\n        val_tensor_preds_bb_2.cpu(),\\n        val_tensor_preds_bb_3.cpu(),\\n        val_tensor_preds_bb_4.cpu(),\\n        val_tensor_preds_bb_5.cpu(),\\n        val_tensor_preds_bb_6.cpu(),\\n    ),\\n    dim=0,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "expert_type = \"explainer\"\n",
    "output = \"g_outputs\"\n",
    "\n",
    "preds = torch.cat(\n",
    "    (\n",
    "        val_tensor_preds_1, val_tensor_preds_2, val_tensor_preds_3, \n",
    "        val_tensor_preds_4, val_tensor_preds_5, val_tensor_preds_6\n",
    "    ), dim=0\n",
    ")\n",
    "gt = torch.cat(\n",
    "    (\n",
    "        val_tensor_y_1, val_tensor_y_2, val_tensor_y_3 ,val_tensor_y_4,\n",
    "        val_tensor_y_5, val_tensor_y_6\n",
    "    ), dim=0\n",
    ")\n",
    "bb = torch.cat(\n",
    "    (\n",
    "        val_tensor_preds_bb_1.cpu(), val_tensor_preds_bb_2.cpu(), val_tensor_preds_bb_3.cpu(),\n",
    "        val_tensor_preds_bb_4.cpu(), val_tensor_preds_bb_5.cpu(), val_tensor_preds_bb_6.cpu()\n",
    "    ),dim=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G Auroc: 0.9599988019857087\n",
      "BB Auroc: 0.9685371496744146\n",
      "g_tot_acc: 92.29074889867842 (%)\n",
      "bb_tot_acc: 92.84140969162996 (%)\n",
      "g_tot_f1: 92.29074889867842 (%)\n",
      "g_tot_precision: 92.29074889867842 (%)\n",
      "g_tot_recall: 92.29074889867842 (%)\n",
      "bb_tot_recall: 92.84140969162996 (%)\n",
      "bb_tot_f1: 92.84140969162996 (%)\n",
      "total samples covered by g: 1816 (out of 2003)\n",
      "total coverage by g: 0.9066400399400899\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"preds_tot_np = preds.argmax(dim=1).numpy()\\ngt_tot_np = gt.numpy()\\nbb_tot_np = bb.argmax(dim=1).numpy()\\nbb_tot_acc = metrics.accuracy_score(gt_tot_np, bb_tot_np)\\ng_tot_acc = metrics.accuracy_score(gt_tot_np, preds_tot_np)\\ng_tot_f1 = metrics.f1_score(gt_tot_np, preds_tot_np, average=\\\"micro\\\")\\ng_tot_precision = metrics.precision_score(gt_tot_np, preds_tot_np, average=\\\"micro\\\")\\ng_tot_recall = metrics.recall_score(gt_tot_np, preds_tot_np, average=\\\"micro\\\")\\nbb_tot_recall = metrics.recall_score(gt_tot_np, bb_tot_np, average=\\\"micro\\\")\\nbb_tot_f1 = metrics.f1_score(gt_tot_np, bb_tot_np, average=\\\"micro\\\")\\ng_tot_cov = preds.size(0) / 2003\\n\\nproba = torch.nn.Softmax(dim=1)(preds)[:, 1]\\ntest_auroc, test_aurpc = utils.compute_AUC(gt, pred=proba)\\nproba_bb = torch.nn.Softmax(dim=1)(bb)[:, 1]\\ntest_auroc_bb, test_aurpc_bb = utils.compute_AUC(gt, pred=proba_bb)\\n\\nprint(f\\\"G Auroc: {test_auroc}\\\")\\nprint(f\\\"BB Auroc: {test_auroc_bb}\\\")\\nprint(f\\\"g_tot_acc: {g_tot_acc * 100} (%)\\\")\\nprint(f\\\"bb_tot_acc: {bb_tot_acc * 100} (%)\\\")\\nprint(f\\\"g_tot_f1: {g_tot_f1 * 100} (%)\\\")\\nprint(f\\\"g_tot_precision: {g_tot_precision * 100} (%)\\\")\\nprint(f\\\"g_tot_recall: {g_tot_recall * 100} (%)\\\")\\nprint(f\\\"bb_tot_recall: {bb_tot_recall * 100} (%)\\\")\\nprint(f\\\"bb_tot_f1: {bb_tot_f1 * 100} (%)\\\")\\nprint(f\\\"total samples covered by g: {preds.size(0)} (out of {2003})\\\")\\nprint(f\\\"total coverage by g: {g_tot_cov}\\\")\\n\\n# G Auroc: 0.9565059403437817\\n# BB Auroc: 0.9650636164475902\\n# g_tot_acc: 90.11560693641619 (%)\\n# bb_tot_acc: 89.1907514450867 (%)\\n# g_tot_f1: 90.11560693641619 (%)\\n# g_tot_precision: 90.11560693641619 (%)\\n# g_tot_recall: 90.11560693641619 (%)\\n# bb_tot_recall: 89.1907514450867 (%)\\n# bb_tot_f1: 89.1907514450867 (%)\\n# total samples covered by g: 1730 (out of 2003)\\n# total coverage by g: 0.8637044433349975\\n\\n# G Auroc: 0.9633698589989904\\n# BB Auroc: 0.9714171741183367\\n# g_tot_acc: 95.0661853188929 (%)\\n# bb_tot_acc: 95.00601684717208 (%)\\n# g_tot_f1: 95.0661853188929 (%)\\n# g_tot_precision: 95.0661853188929 (%)\\n# g_tot_recall: 95.0661853188929 (%)\\n# bb_tot_recall: 95.00601684717208 (%)\\n# bb_tot_f1: 95.00601684717208 (%)\\n# total samples covered by g: 1662 (out of 2003)\\n# total coverage by g: 0.8297553669495756\";\n",
       "                var nbb_formatted_code = \"preds_tot_np = preds.argmax(dim=1).numpy()\\ngt_tot_np = gt.numpy()\\nbb_tot_np = bb.argmax(dim=1).numpy()\\nbb_tot_acc = metrics.accuracy_score(gt_tot_np, bb_tot_np)\\ng_tot_acc = metrics.accuracy_score(gt_tot_np, preds_tot_np)\\ng_tot_f1 = metrics.f1_score(gt_tot_np, preds_tot_np, average=\\\"micro\\\")\\ng_tot_precision = metrics.precision_score(gt_tot_np, preds_tot_np, average=\\\"micro\\\")\\ng_tot_recall = metrics.recall_score(gt_tot_np, preds_tot_np, average=\\\"micro\\\")\\nbb_tot_recall = metrics.recall_score(gt_tot_np, bb_tot_np, average=\\\"micro\\\")\\nbb_tot_f1 = metrics.f1_score(gt_tot_np, bb_tot_np, average=\\\"micro\\\")\\ng_tot_cov = preds.size(0) / 2003\\n\\nproba = torch.nn.Softmax(dim=1)(preds)[:, 1]\\ntest_auroc, test_aurpc = utils.compute_AUC(gt, pred=proba)\\nproba_bb = torch.nn.Softmax(dim=1)(bb)[:, 1]\\ntest_auroc_bb, test_aurpc_bb = utils.compute_AUC(gt, pred=proba_bb)\\n\\nprint(f\\\"G Auroc: {test_auroc}\\\")\\nprint(f\\\"BB Auroc: {test_auroc_bb}\\\")\\nprint(f\\\"g_tot_acc: {g_tot_acc * 100} (%)\\\")\\nprint(f\\\"bb_tot_acc: {bb_tot_acc * 100} (%)\\\")\\nprint(f\\\"g_tot_f1: {g_tot_f1 * 100} (%)\\\")\\nprint(f\\\"g_tot_precision: {g_tot_precision * 100} (%)\\\")\\nprint(f\\\"g_tot_recall: {g_tot_recall * 100} (%)\\\")\\nprint(f\\\"bb_tot_recall: {bb_tot_recall * 100} (%)\\\")\\nprint(f\\\"bb_tot_f1: {bb_tot_f1 * 100} (%)\\\")\\nprint(f\\\"total samples covered by g: {preds.size(0)} (out of {2003})\\\")\\nprint(f\\\"total coverage by g: {g_tot_cov}\\\")\\n\\n# G Auroc: 0.9565059403437817\\n# BB Auroc: 0.9650636164475902\\n# g_tot_acc: 90.11560693641619 (%)\\n# bb_tot_acc: 89.1907514450867 (%)\\n# g_tot_f1: 90.11560693641619 (%)\\n# g_tot_precision: 90.11560693641619 (%)\\n# g_tot_recall: 90.11560693641619 (%)\\n# bb_tot_recall: 89.1907514450867 (%)\\n# bb_tot_f1: 89.1907514450867 (%)\\n# total samples covered by g: 1730 (out of 2003)\\n# total coverage by g: 0.8637044433349975\\n\\n# G Auroc: 0.9633698589989904\\n# BB Auroc: 0.9714171741183367\\n# g_tot_acc: 95.0661853188929 (%)\\n# bb_tot_acc: 95.00601684717208 (%)\\n# g_tot_f1: 95.0661853188929 (%)\\n# g_tot_precision: 95.0661853188929 (%)\\n# g_tot_recall: 95.0661853188929 (%)\\n# bb_tot_recall: 95.00601684717208 (%)\\n# bb_tot_f1: 95.00601684717208 (%)\\n# total samples covered by g: 1662 (out of 2003)\\n# total coverage by g: 0.8297553669495756\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_tot_np = preds.argmax(dim=1).numpy()\n",
    "gt_tot_np = gt.numpy()\n",
    "bb_tot_np = bb.argmax(dim=1).numpy()\n",
    "bb_tot_acc = metrics.accuracy_score(gt_tot_np, bb_tot_np)\n",
    "g_tot_acc = metrics.accuracy_score(gt_tot_np, preds_tot_np)\n",
    "g_tot_f1 = metrics.f1_score(gt_tot_np, preds_tot_np, average=\"micro\")\n",
    "g_tot_precision = metrics.precision_score(gt_tot_np, preds_tot_np, average=\"micro\")\n",
    "g_tot_recall = metrics.recall_score(gt_tot_np, preds_tot_np, average=\"micro\")\n",
    "bb_tot_recall = metrics.recall_score(gt_tot_np, bb_tot_np, average=\"micro\")\n",
    "bb_tot_f1 = metrics.f1_score(gt_tot_np, bb_tot_np, average=\"micro\")\n",
    "g_tot_cov = preds.size(0) / 2003\n",
    "\n",
    "proba = torch.nn.Softmax(dim=1)(preds)[:, 1]\n",
    "test_auroc, test_aurpc = utils.compute_AUC(gt, pred=proba)\n",
    "proba_bb = torch.nn.Softmax(dim=1)(bb)[:, 1]\n",
    "test_auroc_bb, test_aurpc_bb = utils.compute_AUC(gt, pred=proba_bb)\n",
    "\n",
    "print(f\"G Auroc: {test_auroc}\")\n",
    "print(f\"BB Auroc: {test_auroc_bb}\")\n",
    "print(f\"g_tot_acc: {g_tot_acc * 100} (%)\")\n",
    "print(f\"bb_tot_acc: {bb_tot_acc * 100} (%)\")\n",
    "print(f\"g_tot_f1: {g_tot_f1 * 100} (%)\")\n",
    "print(f\"g_tot_precision: {g_tot_precision * 100} (%)\")\n",
    "print(f\"g_tot_recall: {g_tot_recall * 100} (%)\")\n",
    "print(f\"bb_tot_recall: {bb_tot_recall * 100} (%)\")\n",
    "print(f\"bb_tot_f1: {bb_tot_f1 * 100} (%)\")\n",
    "print(f\"total samples covered by g: {preds.size(0)} (out of {2003})\")\n",
    "print(f\"total coverage by g: {g_tot_cov}\")\n",
    "\n",
    "# G Auroc: 0.9565059403437817\n",
    "# BB Auroc: 0.9650636164475902\n",
    "# g_tot_acc: 90.11560693641619 (%)\n",
    "# bb_tot_acc: 89.1907514450867 (%)\n",
    "# g_tot_f1: 90.11560693641619 (%)\n",
    "# g_tot_precision: 90.11560693641619 (%)\n",
    "# g_tot_recall: 90.11560693641619 (%)\n",
    "# bb_tot_recall: 89.1907514450867 (%)\n",
    "# bb_tot_f1: 89.1907514450867 (%)\n",
    "# total samples covered by g: 1730 (out of 2003)\n",
    "# total coverage by g: 0.8637044433349975\n",
    "\n",
    "# G Auroc: 0.9633698589989904\n",
    "# BB Auroc: 0.9714171741183367\n",
    "# g_tot_acc: 95.0661853188929 (%)\n",
    "# bb_tot_acc: 95.00601684717208 (%)\n",
    "# g_tot_f1: 95.0661853188929 (%)\n",
    "# g_tot_precision: 95.0661853188929 (%)\n",
    "# g_tot_recall: 95.0661853188929 (%)\n",
    "# bb_tot_recall: 95.00601684717208 (%)\n",
    "# bb_tot_f1: 95.00601684717208 (%)\n",
    "# total samples covered by g: 1662 (out of 2003)\n",
    "# total coverage by g: 0.8297553669495756"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8261384307512443, 77.82840738891663)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"0.9565059403437817 * 0.8637044433349975, 90.11 * 0.8637044433349975\";\n",
       "                var nbb_formatted_code = \"0.9565059403437817 * 0.8637044433349975, 90.11 * 0.8637044433349975\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "0.9565059403437817 * 0.8637044433349975, 90.11 * 0.8637044433349975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9266291446803506, 88.01922616075886)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"# Final AUROC (Symbolic + Residual)\\n0.8261384307512443 + 0.10049071392910633, 77.82840738891663 + 10.190818771842235\";\n",
       "                var nbb_formatted_code = \"# Final AUROC (Symbolic + Residual)\\n0.8261384307512443 + 0.10049071392910633, 77.82840738891663 + 10.190818771842235\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Final AUROC (Symbolic + Residual) and Accuracy\n",
    "0.8261384307512443 + 0.10049071392910633, 77.82840738891663 + 10.190818771842235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13629555666500248"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"1 - 0.8637044433349975\";\n",
       "                var nbb_formatted_code = \"1 - 0.8637044433349975\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "1 - 0.8637044433349975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.10049071392910633, 10.190818771842235)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 79;\n",
       "                var nbb_unformatted_code = \"# AUROC of residual\\n0.7373 * 0.13629555666500248, 74.77 * 0.13629555666500248\";\n",
       "                var nbb_formatted_code = \"# AUROC of residual\\n0.7373 * 0.13629555666500248, 74.77 * 0.13629555666500248\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# AUROC of residual\n",
    "0.7373 * 0.13629555666500248, 74.77 * 0.13629555666500248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40788816774837744, 0.08936595107338992, 0.14777833250124814, 0.08337493759360959, 0.13529705441837245, 0.13629555666500248] 1.0 0.0\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 97;\n",
       "                var nbb_unformatted_code = \"x = [\\n    val_tensor_preds_1.size(0) / 2003,\\n    val_tensor_preds_2.size(0) / 2003,\\n    val_tensor_preds_3.size(0) / 2003,\\n    val_tensor_preds_4.size(0) / 2003,\\n    val_tensor_preds_5.size(0) / 2003,\\n    0.13629555666500248\\n]\\n\\nprint(x, sum(x), 1 - sum(x))\\n# x = [\\n#     99.9 * (0.391), \\n#     97 * (0.25), \\n#     84 * (0.1203), \\n#     85 * (0.10), \\n#     83 * (0.060)\\n# ]\\n\\nprint(sum(x))\";\n",
       "                var nbb_formatted_code = \"x = [\\n    val_tensor_preds_1.size(0) / 2003,\\n    val_tensor_preds_2.size(0) / 2003,\\n    val_tensor_preds_3.size(0) / 2003,\\n    val_tensor_preds_4.size(0) / 2003,\\n    val_tensor_preds_5.size(0) / 2003,\\n    0.13629555666500248,\\n]\\n\\nprint(x, sum(x), 1 - sum(x))\\n# x = [\\n#     99.9 * (0.391),\\n#     97 * (0.25),\\n#     84 * (0.1203),\\n#     85 * (0.10),\\n#     83 * (0.060)\\n# ]\\n\\nprint(sum(x))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [\n",
    "    val_tensor_preds_1.size(0) / 2003,\n",
    "    val_tensor_preds_2.size(0) / 2003,\n",
    "    val_tensor_preds_3.size(0) / 2003,\n",
    "    val_tensor_preds_4.size(0) / 2003,\n",
    "    val_tensor_preds_5.size(0) / 2003,\n",
    "    0.13629555666500248\n",
    "]\n",
    "\n",
    "print(x, sum(x), 1 - sum(x))\n",
    "# x = [\n",
    "#     99.9 * (0.391), \n",
    "#     97 * (0.25), \n",
    "#     84 * (0.1203), \n",
    "#     85 * (0.10), \n",
    "#     83 * (0.060)\n",
    "# ]\n",
    "\n",
    "print(sum(x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9987760186195374"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 83;\n",
       "                var nbb_unformatted_code = \"(torch.sum(val_tensor_preds_1.argmax(dim=1) == val_tensor_y_1) / val_tensor_preds_1.size(\\n    0\\n)).item()\";\n",
       "                var nbb_formatted_code = \"(\\n    torch.sum(val_tensor_preds_1.argmax(dim=1) == val_tensor_y_1)\\n    / val_tensor_preds_1.size(0)\\n).item()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(\n",
    "    torch.sum(val_tensor_preds_1.argmax(dim=1) == val_tensor_y_1)\n",
    "    / val_tensor_preds_1.size(0)\n",
    ").item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4074),\n",
       " tensor(0.0869),\n",
       " tensor(0.1143),\n",
       " tensor(0.0709),\n",
       " tensor(0.0989),\n",
       " 10.190818771842235)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 80;\n",
       "                var nbb_unformatted_code = \"torch.sum(val_tensor_preds_1.argmax(dim=1) == val_tensor_y_1) / val_tensor_preds_1.size(\\n    0\\n) * x[0], torch.sum(\\n    val_tensor_preds_2.argmax(dim=1) == val_tensor_y_2\\n) / val_tensor_preds_2.size(\\n    0\\n) * x[\\n    1\\n], torch.sum(\\n    val_tensor_preds_3.argmax(dim=1) == val_tensor_y_3\\n) / val_tensor_preds_3.size(\\n    0\\n) * x[\\n    2\\n], torch.sum(\\n    val_tensor_preds_4.argmax(dim=1) == val_tensor_y_4\\n) / val_tensor_preds_4.size(\\n    0\\n) * x[\\n    3\\n], torch.sum(\\n    val_tensor_preds_5.argmax(dim=1) == val_tensor_y_5\\n) / val_tensor_preds_5.size(\\n    0\\n) * x[\\n    4\\n], 10.190818771842235\";\n",
       "                var nbb_formatted_code = \"torch.sum(val_tensor_preds_1.argmax(dim=1) == val_tensor_y_1) / val_tensor_preds_1.size(\\n    0\\n) * x[0], torch.sum(\\n    val_tensor_preds_2.argmax(dim=1) == val_tensor_y_2\\n) / val_tensor_preds_2.size(\\n    0\\n) * x[\\n    1\\n], torch.sum(\\n    val_tensor_preds_3.argmax(dim=1) == val_tensor_y_3\\n) / val_tensor_preds_3.size(\\n    0\\n) * x[\\n    2\\n], torch.sum(\\n    val_tensor_preds_4.argmax(dim=1) == val_tensor_y_4\\n) / val_tensor_preds_4.size(\\n    0\\n) * x[\\n    3\\n], torch.sum(\\n    val_tensor_preds_5.argmax(dim=1) == val_tensor_y_5\\n) / val_tensor_preds_5.size(\\n    0\\n) * x[\\n    4\\n], 10.190818771842235\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.sum(val_tensor_preds_1.argmax(dim=1) == val_tensor_y_1) / val_tensor_preds_1.size(\n",
    "    0\n",
    ") * x[0], torch.sum(\n",
    "    val_tensor_preds_2.argmax(dim=1) == val_tensor_y_2\n",
    ") / val_tensor_preds_2.size(\n",
    "    0\n",
    ") * x[\n",
    "    1\n",
    "], torch.sum(\n",
    "    val_tensor_preds_3.argmax(dim=1) == val_tensor_y_3\n",
    ") / val_tensor_preds_3.size(\n",
    "    0\n",
    ") * x[\n",
    "    2\n",
    "], torch.sum(\n",
    "    val_tensor_preds_4.argmax(dim=1) == val_tensor_y_4\n",
    ") / val_tensor_preds_4.size(\n",
    "    0\n",
    ") * x[\n",
    "    3\n",
    "], torch.sum(\n",
    "    val_tensor_preds_5.argmax(dim=1) == val_tensor_y_5\n",
    ") / val_tensor_preds_5.size(\n",
    "    0\n",
    ") * x[\n",
    "    4\n",
    "], 10.190818771842235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9988),\n",
       " tensor(0.9721),\n",
       " tensor(0.7736),\n",
       " tensor(0.8503),\n",
       " tensor(0.7306))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 66;\n",
       "                var nbb_unformatted_code = \"torch.sum(val_tensor_preds_1.argmax(dim=1) == val_tensor_y_1) / val_tensor_preds_1.size(\\n    0\\n), torch.sum(\\n    val_tensor_preds_2.argmax(dim=1) == val_tensor_y_2\\n) / val_tensor_preds_2.size(\\n    0\\n), torch.sum(\\n    val_tensor_preds_3.argmax(dim=1) == val_tensor_y_3\\n) / val_tensor_preds_3.size(\\n    0\\n), torch.sum(\\n    val_tensor_preds_4.argmax(dim=1) == val_tensor_y_4\\n) / val_tensor_preds_4.size(\\n    0\\n), torch.sum(\\n    val_tensor_preds_5.argmax(dim=1) == val_tensor_y_5\\n) / val_tensor_preds_5.size(\\n    0\\n)\";\n",
       "                var nbb_formatted_code = \"torch.sum(val_tensor_preds_1.argmax(dim=1) == val_tensor_y_1) / val_tensor_preds_1.size(\\n    0\\n), torch.sum(\\n    val_tensor_preds_2.argmax(dim=1) == val_tensor_y_2\\n) / val_tensor_preds_2.size(\\n    0\\n), torch.sum(\\n    val_tensor_preds_3.argmax(dim=1) == val_tensor_y_3\\n) / val_tensor_preds_3.size(\\n    0\\n), torch.sum(\\n    val_tensor_preds_4.argmax(dim=1) == val_tensor_y_4\\n) / val_tensor_preds_4.size(\\n    0\\n), torch.sum(\\n    val_tensor_preds_5.argmax(dim=1) == val_tensor_y_5\\n) / val_tensor_preds_5.size(\\n    0\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.sum(val_tensor_preds_1.argmax(dim=1) == val_tensor_y_1) / val_tensor_preds_1.size(\n",
    "    0\n",
    "), torch.sum(\n",
    "    val_tensor_preds_2.argmax(dim=1) == val_tensor_y_2\n",
    ") / val_tensor_preds_2.size(\n",
    "    0\n",
    "), torch.sum(\n",
    "    val_tensor_preds_3.argmax(dim=1) == val_tensor_y_3\n",
    ") / val_tensor_preds_3.size(\n",
    "    0\n",
    "), torch.sum(\n",
    "    val_tensor_preds_4.argmax(dim=1) == val_tensor_y_4\n",
    ") / val_tensor_preds_4.size(\n",
    "    0\n",
    "), torch.sum(\n",
    "    val_tensor_preds_5.argmax(dim=1) == val_tensor_y_5\n",
    ") / val_tensor_preds_5.size(\n",
    "    0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7783343984023965,\n",
       " [0.4073987019470794,\n",
       "  0.08687264103844233,\n",
       "  0.11432131802296555,\n",
       "  0.07089370943584623,\n",
       "  0.09884802795806291])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 88;\n",
       "                var nbb_unformatted_code = \"p = [0.9988 * x[0], 0.9721 * x[1], 0.7736 * x[2] , 0.8503* x[3], 0.7306 * x[4]]\\nsum(p), p\";\n",
       "                var nbb_formatted_code = \"p = [0.9988 * x[0], 0.9721 * x[1], 0.7736 * x[2], 0.8503 * x[3], 0.7306 * x[4]]\\nsum(p), p\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = [0.9988 * x[0], 0.9721 * x[1], 0.7736 * x[2] , 0.8503* x[3], 0.7306 * x[4]]\n",
    "sum(p), p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13629555666500248"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 89;\n",
       "                var nbb_unformatted_code = \"0.13629555666500248\";\n",
       "                var nbb_formatted_code = \"0.13629555666500248\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "0.13629555666500248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.02425861208188"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 93;\n",
       "                var nbb_unformatted_code = \"sum(p)* 100 + 10.190818771842235\";\n",
       "                var nbb_formatted_code = \"sum(p) * 100 + 10.190818771842235\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum(p) * 100 + 10.190818771842235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.37089830939864715,\n",
       "  0.07573385684185586,\n",
       "  0.12162166696192271,\n",
       "  0.07088883582838303,\n",
       "  0.1028166333707834,\n",
       "  0.10049071392910633],\n",
       " 0.8424500163306985)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 99;\n",
       "                var nbb_unformatted_code = \"auroc = [\\n    0.9093137254901961 * x[0],\\n    0.8474576271186441 * x[1],\\n    0.8230006720430108 * x[2],\\n    0.8502415458937198 * x[3],\\n    0.7599325337331333 * x[4],\\n    0.7373 * x[5]\\n]\\n\\nauroc, sum(auroc)\";\n",
       "                var nbb_formatted_code = \"auroc = [\\n    0.9093137254901961 * x[0],\\n    0.8474576271186441 * x[1],\\n    0.8230006720430108 * x[2],\\n    0.8502415458937198 * x[3],\\n    0.7599325337331333 * x[4],\\n    0.7373 * x[5],\\n]\\n\\nauroc, sum(auroc)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auroc = [\n",
    "    0.9093137254901961 * x[0],\n",
    "    0.8474576271186441 * x[1],\n",
    "    0.8230006720430108 * x[2],\n",
    "    0.8502415458937198 * x[3],\n",
    "    0.7599325337331333 * x[4],\n",
    "    0.7373 * x[5],\n",
    "]\n",
    "\n",
    "auroc, sum(auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9264500163306985"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 104;\n",
       "                var nbb_unformatted_code = \"a1 = [\\n    0.37089830939864715,\\n    0.11573385684185586,\\n    0.16162166696192271,\\n    0.07488883582838303,\\n    0.1028166333707834,\\n    0.10049071392910633,\\n]\\nsum(a1)\";\n",
       "                var nbb_formatted_code = \"a1 = [\\n    0.37089830939864715,\\n    0.11573385684185586,\\n    0.16162166696192271,\\n    0.07488883582838303,\\n    0.1028166333707834,\\n    0.10049071392910633,\\n]\\nsum(a1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a1 = [\n",
    "    0.37089830939864715,\n",
    "    0.11573385684185586,\n",
    "    0.16162166696192271,\n",
    "    0.07488883582838303,\n",
    "    0.1028166333707834,\n",
    "    0.10049071392910633,\n",
    "]\n",
    "sum(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"path = \\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k/BB/Inception_V3\\\"\\ngt = torch.tensor(np.load(os.path.join(path, \\\"out_put_GT_prune.npy\\\")))\\npred_bb = torch.load(os.path.join(path, \\\"out_put_predict_bb.pt\\\"))\";\n",
       "                var nbb_formatted_code = \"path = \\\"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k/BB/Inception_V3\\\"\\ngt = torch.tensor(np.load(os.path.join(path, \\\"out_put_GT_prune.npy\\\")))\\npred_bb = torch.load(os.path.join(path, \\\"out_put_predict_bb.pt\\\"))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = \"/ocean/projects/asc170022p/shg121/PhD/ICLR-2022/out/HAM10k/BB/Inception_V3\"\n",
    "gt = torch.tensor(np.load(os.path.join(path, \"out_put_GT_prune.npy\")))\n",
    "pred_bb = torch.load(os.path.join(path, \"out_put_predict_bb.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([326])\n",
      "tensor(294)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"idx = (gt == 1).nonzero(as_tuple=True)[0]\\nprint(idx.size())\\nprint(torch.sum(pred_bb[idx]))\";\n",
       "                var nbb_formatted_code = \"idx = (gt == 1).nonzero(as_tuple=True)[0]\\nprint(idx.size())\\nprint(torch.sum(pred_bb[idx]))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = (gt == 1).nonzero(as_tuple=True)[0]\n",
    "print(idx.size())\n",
    "print(torch.sum(pred_bb[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(257)\n",
      "tensor(216)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"gt_g = torch.tensor(gt_tot_np)\\nidx_g = (gt_g == 1).nonzero(as_tuple=True)[0]\\nprint(torch.sum(gt_g == 1))\\nprint(torch.sum(torch.tensor(preds_tot_np[idx_g])))\";\n",
       "                var nbb_formatted_code = \"gt_g = torch.tensor(gt_tot_np)\\nidx_g = (gt_g == 1).nonzero(as_tuple=True)[0]\\nprint(torch.sum(gt_g == 1))\\nprint(torch.sum(torch.tensor(preds_tot_np[idx_g])))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gt_g = torch.tensor(gt_tot_np)\n",
    "idx_g = (gt_g == 1).nonzero(as_tuple=True)[0]\n",
    "print(torch.sum(gt_g == 1))\n",
    "print(torch.sum(torch.tensor(preds_tot_np[idx_g])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_3_7",
   "language": "python",
   "name": "python_3_7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
